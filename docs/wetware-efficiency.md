# Wetware Efficiency

Token efficiency optimises the LLM's scarce resource — context window
capacity. Wetware efficiency optimises the operator's scarce resource —
cognition. Both halves of the dyad have hard limits. Both degrade when
those limits are wasted. But the mechanisms differ because the
architectures differ, and the operator's efficiency compounds across
engagements in a way the LLM's does not.

## The operator is the scarce resource

The LLM is fast, stateless, and replaceable. Swap Claude for GPT, the
pipeline still runs. The operator is slow, stateful, and irreplaceable.
They carry institutional memory, domain intuition, relationship context,
and political awareness that no model has access to. The engagement's
quality ceiling is set by the operator's ability to exercise judgment —
to notice what the model missed, to reject what the model got wrong, and
to contribute signal the model cannot generate.

The operator is also finite. They have bounded attention, limited working
memory, session-length fatigue curves, and competing demands on their
time. Every minute spent parsing a poorly structured deliverable is a
minute not spent exercising the judgment that only they can provide.

Wetware efficiency is the discipline of not wasting the operator's
cognitive budget on work the system should have done for them, so that
their full capacity is available for work only they can do.

## Three roles in the dyad

The operator fills three roles that the agent cannot:

**Sensor.** The operator reads signals from the socio-economic
environment that the agent has no access to. Organisational politics,
stakeholder body language, market rumours, the tone in a client's voice
when they say "that's fine." These signals are invisible to the model
and decisive for the engagement. A sensor that does not understand the
analytical framework it is feeding cannot distinguish signal from noise.

**Actuator.** The operator takes actions in the real world — presents
findings to boards, negotiates with stakeholders, redirects budgets,
hires and fires. The agent produces analysis. The operator converts
analysis into organisational change. An actuator that does not
understand the analysis it is acting on will act on it incorrectly, or
will act on it correctly in the wrong context.

**Insight generator.** The operator synthesises judgment from the
intersection of the agent's analysis and their own lived experience.
"The model says this component is genesis-stage, but I watched this
market for ten years and I know three incumbents are about to ship."
This is the highest-value contribution the operator makes — pattern
completion across information sources that the model cannot access. An
insight generator that does not understand the analytical vocabulary
cannot articulate the insight, even when they feel it.

All three roles improve with understanding. A sensor who understands
evolution theory notices more relevant signals. An actuator who
understands the strategic rationale presents more convincingly. An
insight generator who speaks the analytical language contributes more
precisely. The operator's effectiveness in the dyad is a function of
their comprehension.

## The cost model for wetware

Token economics identifies three costs that compound in the context
window: financial, attention, and displacement. Wetware economics has
an analogous cost model with different mechanics.

### Cognitive load

Working memory holds roughly four chunks simultaneously (Cowan's
revised estimate, down from Miller's 7±2). Every concept the operator
must hold in mind while evaluating a proposal consumes a chunk. A
proposal that requires the operator to simultaneously track the
strategic rationale, the evidence chain, the methodology mechanics, and
the political implications is already at capacity. Adding a fifth
dimension — "and by the way, here is how Wardley's evolution axis
works" — means something falls out.

The system's job is to manage what occupies those chunks. Present the
strategic rationale when it is decision-time. Present methodology
mechanics when they illuminate, not when they distract. Never force the
operator to hold infrastructure knowledge (how the pipeline works)
alongside domain knowledge (what the map means) at the same moment.

### Attention fatigue

Attention is depletable. The operator arrives with a budget; each
decision, each evaluation, each context switch draws it down. A long
proposal with buried conclusions forces the operator to maintain
attention through material that does not require their judgment, just
to reach the part that does. This is the wetware equivalent of
displacement cost: low-value content occupying space that high-value
content needs.

Front-load what requires operator judgment. Put conclusions before
evidence. Put decision points before supporting analysis. The operator
should encounter the material that needs their brain first, while
their budget is fullest.

### Background knowledge debt

The operator who lacks the vocabulary to parse a proposal must spend
cognitive effort on translation before they can spend it on evaluation.
"This component is at evolution stage II (custom-built)" requires the
operator to recall what stage II means, what custom-built implies about
sourcing, and why it matters — before they can assess whether the
positioning is correct.

This is background knowledge debt. It compounds: each gap forces
translation effort at every encounter. Paying it down — building the
operator's fluency with the analytical vocabulary — reduces the per-
interaction cognitive cost permanently. A fluent operator reads "stage
II custom-built" and immediately reasons about sourcing implications
without translation overhead.

## Pedagogy as compounding investment

Teaching the operator is not overhead. It is the highest-leverage
activity the system can perform, because its returns compound across
every subsequent interaction.

### The compounding mechanism

An operator who understands evolution theory does not just evaluate
the current map better. They notice evolution signals during client
conversations (sensor improvement). They explain evolution dynamics
to stakeholders without agent assistance (actuator improvement). They
challenge the agent's evolution assessments from experience (insight
generator improvement). One investment in understanding multiplies
across all three roles and all future engagements.

This is the asymmetry between the two halves of the dyad. The LLM does
not learn from engagement to engagement — each session starts fresh.
The operator does learn, and that learning persists. Every unit of
understanding the system builds in the operator is a permanent
improvement to the dyad's capability. Every unit it fails to build is a
permanent limitation.

### Teaching through the work, not about the work

Effective pedagogy does not pause the engagement to deliver a lecture.
It structures the engagement's own output so that comprehension is a
side effect of participation.

When the agent proposes user needs, it does not just list them. It
shows the reasoning chain: "Research finding X suggests user group Y
has need Z, because..." The operator evaluates the proposal and, in
doing so, learns how user needs are derived from research. Next time,
they are faster. The time after that, they anticipate.

When the agent positions a component on the evolution axis, it does
not just state the position. It names the characteristics that drove
the assessment: "Ubiquity is low, certainty is low, market examples
are few — this is genesis." The operator evaluates the positioning
and, in doing so, internalises the evolution characteristics. They
begin to assess evolution independently.

The propose-negotiate-agree loop is a pedagogical mechanism, not just
a quality mechanism. Each cycle teaches the operator something about
the methodology, if the proposals are structured to make the reasoning
visible.

## Comprehension enables negotiation

The propose-negotiate-agree loop is the engagement's quality gate. The
operator's ability to negotiate — to push back on wrong assessments,
request missing analysis, redirect the approach — depends entirely on
their comprehension of what they are evaluating.

### The rubber-stamp failure mode

An operator who does not understand the proposal cannot negotiate it.
They can only accept or reject wholesale. Wholesale acceptance
degrades the dyad to a single-agent system with human latency — the
model proposes, the human stamps, and the quality gate provides no
value. Wholesale rejection sends the agent back without useful signal.

The system that maximises short-term throughput by minimising
explanation creates operators who rubber-stamp. The system that
invests in operator comprehension creates operators who negotiate
effectively. The first is faster per gate. The second produces better
gates, better operators, and better engagements — and gets faster as
the operator's fluency grows.

### Negotiation as calibration

The operator's disagreements are the most valuable signal the dyad
produces. When the operator says "that evolution assessment is wrong —
I know three competitors about to commoditise this," the agent
receives information it could not have generated. This signal emerges
only when the operator understands the assessment well enough to
identify the specific claim they disagree with.

"I don't like this" is low-resolution feedback. "The evolution
position is wrong because the market has more suppliers than this
assessment accounts for" is high-resolution feedback. The difference
is comprehension. Every investment in the operator's understanding of
the analytical framework increases the resolution of their feedback,
which increases the precision of the agent's revisions, which
increases the quality of the final artifact.

## Pedagogical affordances in output design

The outbound direction in prompt engineering
(see `docs/prompt-engineering.md` § Style as affordance) describes
style as the interface adapter between the LLM's token-processing
architecture and the human's pattern-matching architecture. Wetware
efficiency extends this: style is not just an affordance for reception
but an affordance for learning.

### Make reasoning visible

Present the conclusion, then the reasoning chain that produced it. The
operator evaluates the conclusion (their job) and absorbs the reasoning
method (pedagogical side effect). Over time, the operator internalises
the reasoning patterns and can generate them independently.

This is the opposite of the dense-summary approach that token
efficiency recommends for inbound (LLM-facing) communication. The
outbound direction should be informationally rich enough that the
operator's mental model grows with each exposure. Not verbose — rich.
The distinction: verbosity adds words without adding understanding;
richness adds the specific detail that enables understanding.

### Name the concepts

Use the canonical vocabulary: "evolution stage," "value chain,"
"inertia," "doctrine." Do not simplify to colloquial alternatives.
The operator needs to acquire the terminology to participate
effectively in the methodology. Every encounter with the correct term
in context is a reinforcement. Every avoidance of it is a missed
opportunity.

This is the opposite of the "write for a general audience" instinct.
The operator is not a general audience. They are a practitioner in
training. Practitioners need terminology, not paraphrase.

### Show the evidence chain

Connect findings to their source material. "Research report X (§ Y)
indicates Z, which suggests component A is at evolution stage II."
The operator can trace the chain, verify the inference, and — over
repeated exposures — learn how evidence chains are constructed in this
methodology. The traceability serves quality (the operator can check
the work) and pedagogy (the operator learns the method) simultaneously.

### Use the methodology's own structure

Present Wardley Mapping findings in terms of evolution, value chains,
and strategic plays — not in generic business language. Present BMC
findings in terms of segments, value propositions, and channels — not
in consultant-speak. The methodology's structure is the pedagogical
scaffolding. Using it consistently builds the operator's fluency with
the framework.

## The long game

The operator's long-term interest is not to have a good engagement. It
is to become the kind of operator who produces good engagements
reliably. The difference is capability accumulation.

### Dependency vs capability

A system that produces excellent output the operator does not
understand creates dependency. The operator cannot function without
the system, cannot evaluate the system's output independently, and
cannot transfer what they learned to contexts where the system is not
available. This is the consulting industry's original failure mode:
the client pays for answers they do not understand and cannot reproduce.

A system that produces excellent output the operator progressively
understands creates capability. The operator's independent judgment
improves. Their ability to commission and evaluate analytical work —
with this system or any other — improves. Their value as the
sensor/actuator/insight-generator component of the dyad increases with
each engagement.

Capability building is not altruistic. The capable operator is a
better dyad partner. They generate higher-resolution signal, take more
precise action, and produce more valuable insights. The system that
builds operator capability improves its own performance by improving
its collaborator.

### The graduation gradient

Not all operators start at the same level. Not all engagements require
the same depth of understanding. The system should calibrate
pedagogical investment to the operator's current level and the
engagement's requirements.

An operator new to Wardley Mapping needs evolution theory explained in
context, repeatedly, with examples drawn from the current engagement.
An experienced operator needs only the assessment and the evidence —
they supply the theoretical framework themselves. The system should
detect this (from the operator's negotiation behaviour — fluent
operators negotiate at higher resolution) and adjust.

This parallels freedom levels in skill design. A high-freedom skill
gives the agent latitude because the task tolerates variation. A
high-fluency operator gets less pedagogical scaffolding because they
need less. The calibration is continuous, not a mode switch.

## Implications for skill design

### Proposals should teach, not just propose

A skill's proposal output should make the reasoning chain visible. Not
"here are the user needs" but "here are the user needs, derived from
research findings X, Y, Z, using criteria A, B, C." The operator
evaluates the needs and absorbs the derivation method.

### Gate artifacts should be self-explanatory

A gate artifact that the operator agreed to should be understandable
six months later without reconstructing the conversation that produced
it. It should name the methodology concepts it embodies, cite the
evidence it rests on, and state the reasoning that connects them. This
serves both cross-session memory (the agent's need) and long-term
comprehension (the operator's need).

### The editorial voice is a pedagogical instrument

The Consultamatron editorial voice is not just a brand exercise. It is
a pedagogical affordance. The voice is procedural and competent — it
explains things clearly because unclear explanations waste time. This
competence-oriented delivery activates the operator's professional
pattern-matching: they receive the material as expert communication
to be engaged with, not as AI output to be evaluated for plausibility.

The voice never talks down. It never simplifies. It explains precisely
and moves on. The operator either keeps up or asks questions. Both
outcomes serve the pedagogical goal: keeping up builds fluency; asking
questions identifies gaps.

## Relationship to token efficiency

Token efficiency and wetware efficiency are dual problems with
complementary solutions:

| | Token efficiency | Wetware efficiency |
|---|---|---|
| **Scarce resource** | Context window capacity | Operator cognition |
| **Cost model** | Financial, attention, displacement | Cognitive load, fatigue, knowledge debt |
| **Optimisation** | Compress, structure, discard | Scaffold, sequence, reinforce |
| **Inbound principle** | Compile to semantic bytecode | n/a (human is not receiving inbound) |
| **Outbound principle** | n/a (LLM does not need style) | Teach through structured delivery |
| **Compounds across** | Nothing (stateless) | Engagements (operator learns) |
| **Investment metaphor** | Spend less | Invest wisely |

Token efficiency asks: how do we spend fewer tokens? Wetware efficiency
asks: how do we spend operator cognition on the right things? The
semantic waist serves both — it replaces expensive prose-parsing (tokens
and cognition) with cheap structured data (zero tokens and minimal
cognitive load).

The directional model in prompt engineering captures the boundary:
inbound is token-efficient (compiled for the machine), outbound is
wetware-efficient (structured for human comprehension and learning).
The engagement produces better outcomes when both halves of the dyad
operate within their efficiency budget.
